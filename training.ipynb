{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b401f357",
   "metadata": {},
   "source": [
    "Fine tuning sentence-transformers/all-MiniLM-L12-v2 with  enron email dataset and LoRa with peft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e442ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers datasets torch peft pandas scikit-learn safetensors sentence-transformers\n",
    "%pip install \"numpy<2.0.0\"\n",
    "%pip install kaggle kagglehub\n",
    "%pip install seaborn matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a4e5409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset, Features, Value, ClassLabel\n",
    "import safetensors # Required for use_safetensors=True and safe_serialization=True\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import kagglehub\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# Force CPU\n",
    "torch.cuda.is_available = lambda: False\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26ab6dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/wcukierski/enron-email-dataset?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 358M/358M [01:25<00:00, 4.41MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/rodneyfinkel/.cache/kagglehub/datasets/wcukierski/enron-email-dataset/versions/2\n"
     ]
    }
   ],
   "source": [
    "# download dataset, kaggle will download to cache \n",
    "path = kagglehub.dataset_download(\"wcukierski/enron-email-dataset\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b4905e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copied emails.csv to current working directory.\n",
      "Original cached dataset removed.\n"
     ]
    }
   ],
   "source": [
    "# move kaggle dataset to current working directory\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    src = os.path.join(path, filename)\n",
    "    dst = os.path.join(\".\", filename)\n",
    "    if os.path.isfile(src):\n",
    "        shutil.copy(src, dst)\n",
    "        print(f\"copied {filename} to current working directory.\")\n",
    "        # Remove the orginal cached dataset\n",
    "        cache_path = os.path.expanduser(\"~/.cache/kagglehub/datasets/wcukierski/enron-email-dataset\")\n",
    "        shutil.rmtree(cache_path)\n",
    "        print(\"Original cached dataset removed.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8201e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess dataset\n",
    "df = pd.read_csv('emails.csv')\n",
    "df = df.sample(n=20000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "518b8bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>427616</th>\n",
       "      <td>shackleton-s/sent/1912.</td>\n",
       "      <td>Message-ID: &lt;21013688.1075844564560.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108773</th>\n",
       "      <td>farmer-d/logistics/1066.</td>\n",
       "      <td>Message-ID: &lt;22688499.1075854130303.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355471</th>\n",
       "      <td>parks-j/deleted_items/202.</td>\n",
       "      <td>Message-ID: &lt;27817771.1075841359502.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457837</th>\n",
       "      <td>stokley-c/chris_stokley/iso/client_rep/41.</td>\n",
       "      <td>Message-ID: &lt;10695160.1075858510449.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124910</th>\n",
       "      <td>germany-c/all_documents/1174.</td>\n",
       "      <td>Message-ID: &lt;27819143.1075853689038.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              file  \\\n",
       "427616                     shackleton-s/sent/1912.   \n",
       "108773                    farmer-d/logistics/1066.   \n",
       "355471                  parks-j/deleted_items/202.   \n",
       "457837  stokley-c/chris_stokley/iso/client_rep/41.   \n",
       "124910               germany-c/all_documents/1174.   \n",
       "\n",
       "                                                  message  \n",
       "427616  Message-ID: <21013688.1075844564560.JavaMail.e...  \n",
       "108773  Message-ID: <22688499.1075854130303.JavaMail.e...  \n",
       "355471  Message-ID: <27817771.1075841359502.JavaMail.e...  \n",
       "457837  Message-ID: <10695160.1075858510449.JavaMail.e...  \n",
       "124910  Message-ID: <27819143.1075853689038.JavaMail.e...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d31445ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean emails and extract subject and delete dates\n",
    "def clean_email(text):\n",
    "    # extract subject if available\n",
    "    subject_match = re.search(r'Subject: (.*?)\\n', text, re.IGNORECASE)\n",
    "    subject = subject_match.group(1) if subject_match else ''\n",
    "    # Remove headers, signatures and dates\n",
    "    text = re.sub(r'From:.*\\n|To:.*\\n|Subject:.*\\n|Message-ID:.*\\n|Date:.*\\n', '', text)\n",
    "    text = re.sub(r'-{2,}.*?-{2,}', '', text)\n",
    "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
    "    return text.strip(), subject\n",
    "\n",
    "df['message'], df['subject'] = zip(*df['message'].apply(clean_email))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58435fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam distribution: is_spam\n",
      "False    19654\n",
      "True       346\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Heursitic spam detection\n",
    "def is_spam(email_text, subject):\n",
    "    full_text = f\"{subject.lower()} {email_text.lower()}\"\n",
    "    spam_keywords = {'offer': 2, 'free': 2, 'win': 3, 'lottery': 3, 'click here': 3}\n",
    "    legit_keywords = {'budget': -2, 'contract': -2, 'meeting': -2}\n",
    "    score = 0\n",
    "    for kw, weight in spam_keywords.items():\n",
    "        if re.search(r'\\b' + re.escape(kw) + r'\\b', full_text):\n",
    "            score += weight\n",
    "    for kw, weight in legit_keywords.items():\n",
    "        if re.search(r'\\b' + re.escape(kw) + r'\\b', full_text):\n",
    "            score += weight\n",
    "    return score > 4\n",
    "\n",
    "df['is_spam'] = df.apply(lambda x: is_spam(x['message'], x['subject']), axis=1)\n",
    "print(\"Spam distribution:\", df['is_spam'].value_counts())\n",
    "df = df[~df['is_spam']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c056d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f8742d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de399ebd28054550bb137faf11c75b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/615 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/Users/rodneyfinkel/Documents/Github/email_classifier_agent/env/lib/python3.12/site-packages/threadpoolctl.py:1226: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Prepare text for embedding (combine subject and body)\n",
    "df['full_text'] = df.apply(lambda x: f\"[SUBJECT] {x['subject']} [BODY] {x['message']}\", axis=1)\n",
    "\n",
    "# Load lightweight model (L6-v2 for efficiency, ~80MB, fast on CPU)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings (batch_size=32 to manage memory ~2GB for 20k samples)\n",
    "embeddings = model.encode(df['full_text'].tolist(), batch_size=32, show_progress_bar=True)\n",
    "\n",
    "# Cluster for categories (k=4) - adjust k if needed\n",
    "kmeans_cat = KMeans(n_clusters=4, random_state=42)\n",
    "df['category_cluster'] = kmeans_cat.fit_predict(embeddings)\n",
    "\n",
    "# Cluster for priorities (k=3, or try more for sub-groups)\n",
    "kmeans_prio = KMeans(n_clusters=3, random_state=42)\n",
    "df['priority_cluster'] = kmeans_prio.fit_predict(embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7186e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category Cluster 0 top keywords: ['20' '2001' 'bcc' 'cc' 'com' 'content' 'ect' 'enron' 'subject' 'version']\n",
      "Category Cluster 1 top keywords: ['20' 'bcc' 'cc' 'com' 'content' 'ect' 'enron' 'subject' 'type' 'version']\n",
      "Category Cluster 2 top keywords: ['20' 'cc' 'cn' 'com' 'content' 'ect' 'enron' 'na' 'ou' 'recipients']\n",
      "Category Cluster 3 top keywords: ['bcc' 'cc' 'charset' 'content' 'folder' 'mime' 'subject' 'text' 'type'\n",
      " 'version']\n",
      "Priority Cluster 0 top keywords: ['20' '2001' 'bcc' 'cc' 'com' 'content' 'ect' 'enron' 'subject' 'version']\n",
      "Priority Cluster 1 top keywords: ['bcc' 'cc' 'com' 'content' 'ect' 'enron' 'folder' 'text' 'type' 'version']\n",
      "Priority Cluster 2 top keywords: ['20' 'cc' 'cn' 'com' 'content' 'ect' 'enron' 'na' 'ou' 'recipients']\n"
     ]
    }
   ],
   "source": [
    "# Extract top keywords per cluster for heuristic refinement/very noisy data at this point\n",
    "def get_top_keywords(texts, n=10):\n",
    "    vectorizer = TfidfVectorizer(max_features=n, stop_words='english')\n",
    "    tfidf = vectorizer.fit_transform(texts)\n",
    "    return vectorizer.get_feature_names_out()\n",
    "\n",
    "# For category clusters\n",
    "for cluster in range(4):\n",
    "    cluster_text = df[df['category_cluster'] == cluster]['full_text']\n",
    "    print(f\"Category Cluster {cluster} top keywords: {get_top_keywords(cluster_text)}\")\n",
    "\n",
    "# For priority clusters\n",
    "for cluster in range(3):\n",
    "    cluster_text = df[df['priority_cluster'] == cluster]['full_text']\n",
    "    print(f\"Priority Cluster {cluster} top keywords: {get_top_keywords(cluster_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40d064ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo-labeled category distribution:\n",
      "category\n",
      "0    9006\n",
      "1    4606\n",
      "3    3719\n",
      "2    2323\n",
      "Name: count, dtype: int64\n",
      "Pseudo-labeled priority distribution:\n",
      "priority\n",
      "0    10777\n",
      "1     6486\n",
      "2     2391\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Example: Map clusters to labels (manual or heuristic-based on keywords)\n",
    "cluster_to_category = {0: 0, 1: 1, 2: 2, 3: 3}  # Adjust based on keyword inspection\n",
    "df['category'] = df['category_cluster'].map(cluster_to_category)\n",
    "\n",
    "# Similarly for priority\n",
    "cluster_to_priority = {0: 0, 1: 1, 2: 2}\n",
    "df['priority'] = df['priority_cluster'].map(cluster_to_priority)\n",
    "\n",
    "print(\"Pseudo-labeled category distribution:\")\n",
    "print(df['category'].value_counts())\n",
    "print(\"Pseudo-labeled priority distribution:\")\n",
    "print(df['priority'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a5fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heuristic spam labeling\n",
    "# def is_potential_spam(text, subject):\n",
    "#     spam_keywords = ['offer', 'free', 'win', 'click here', 'urgent', 'limited time', 'act now']\n",
    "#     return any(keyword in text.lower() or keyword in subject.lower() for keyword in spam_keywords)\n",
    "\n",
    "# df['label'] = df.apply(lambda x: is_potential_spam(x['message'], x['subject']), axis=1).astype(int)\n",
    "\n",
    "# spam = df[df['label'] == 1]\n",
    "# non_spam = df[df['label'] == 0]\n",
    "# target_spam_count = int(len(df) * 0.05)\n",
    "\n",
    "# if len(spam) > target_spam_count:\n",
    "#     print(f\"Reducing spam emails from {len(spam)} to {target_spam_count}\")\n",
    "#     spam = resample(spam, n_samples=target_spam_count, random_state=42)\n",
    "# else:\n",
    "#     non_spam = resample(non_spam, n_samples=int(target_spam_count * 3), random_state=42)\n",
    "\n",
    "# df = pd.concat([spam, non_spam]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "# df.drop(columns=['label'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74fa2583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19654, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "      <th>subject</th>\n",
       "      <th>is_spam</th>\n",
       "      <th>full_text</th>\n",
       "      <th>category_cluster</th>\n",
       "      <th>priority_cluster</th>\n",
       "      <th>category</th>\n",
       "      <th>priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>427616</th>\n",
       "      <td>shackleton-s/sent/1912.</td>\n",
       "      <td>Mime-Version: 1.0\\nContent-Type: text/plain; c...</td>\n",
       "      <td>Re: Credit Derivatives</td>\n",
       "      <td>False</td>\n",
       "      <td>[SUBJECT] Re: Credit Derivatives [BODY] Mime-V...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108773</th>\n",
       "      <td>farmer-d/logistics/1066.</td>\n",
       "      <td>Cc: daren.farmer@enron.com\\nMime-Version: 1.0\\...</td>\n",
       "      <td>Meter #1591 Lamay Gaslift</td>\n",
       "      <td>False</td>\n",
       "      <td>[SUBJECT] Meter #1591 Lamay Gaslift [BODY] Cc:...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355471</th>\n",
       "      <td>parks-j/deleted_items/202.</td>\n",
       "      <td>wollam.erik@enron.com, corrier.brad@enron.com\\...</td>\n",
       "      <td>Re: man night again?</td>\n",
       "      <td>False</td>\n",
       "      <td>[SUBJECT] Re: man night again? [BODY] wollam.e...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457837</th>\n",
       "      <td>stokley-c/chris_stokley/iso/client_rep/41.</td>\n",
       "      <td>Mime-Version: 1.0\\nContent-Type: text/plain; c...</td>\n",
       "      <td>Enron 480, 1480 charges</td>\n",
       "      <td>False</td>\n",
       "      <td>[SUBJECT] Enron 480, 1480 charges [BODY] Mime-...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124910</th>\n",
       "      <td>germany-c/all_documents/1174.</td>\n",
       "      <td>Mime-Version: 1.0\\nContent-Type: text/plain; c...</td>\n",
       "      <td>Transport Deal</td>\n",
       "      <td>False</td>\n",
       "      <td>[SUBJECT] Transport Deal [BODY] Mime-Version: ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              file  \\\n",
       "427616                     shackleton-s/sent/1912.   \n",
       "108773                    farmer-d/logistics/1066.   \n",
       "355471                  parks-j/deleted_items/202.   \n",
       "457837  stokley-c/chris_stokley/iso/client_rep/41.   \n",
       "124910               germany-c/all_documents/1174.   \n",
       "\n",
       "                                                  message  \\\n",
       "427616  Mime-Version: 1.0\\nContent-Type: text/plain; c...   \n",
       "108773  Cc: daren.farmer@enron.com\\nMime-Version: 1.0\\...   \n",
       "355471  wollam.erik@enron.com, corrier.brad@enron.com\\...   \n",
       "457837  Mime-Version: 1.0\\nContent-Type: text/plain; c...   \n",
       "124910  Mime-Version: 1.0\\nContent-Type: text/plain; c...   \n",
       "\n",
       "                          subject  is_spam  \\\n",
       "427616     Re: Credit Derivatives    False   \n",
       "108773  Meter #1591 Lamay Gaslift    False   \n",
       "355471       Re: man night again?    False   \n",
       "457837    Enron 480, 1480 charges    False   \n",
       "124910             Transport Deal    False   \n",
       "\n",
       "                                                full_text  category_cluster  \\\n",
       "427616  [SUBJECT] Re: Credit Derivatives [BODY] Mime-V...                 0   \n",
       "108773  [SUBJECT] Meter #1591 Lamay Gaslift [BODY] Cc:...                 0   \n",
       "355471  [SUBJECT] Re: man night again? [BODY] wollam.e...                 1   \n",
       "457837  [SUBJECT] Enron 480, 1480 charges [BODY] Mime-...                 0   \n",
       "124910  [SUBJECT] Transport Deal [BODY] Mime-Version: ...                 3   \n",
       "\n",
       "        priority_cluster  category  priority  \n",
       "427616                 0         0         0  \n",
       "108773                 0         0         0  \n",
       "355471                 1         1         1  \n",
       "457837                 0         0         0  \n",
       "124910                 1         3         1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec613611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heuristic category labeling\n",
    "# def assign_category(text, subject, file):\n",
    "#     text = text.lower()\n",
    "#     subject = subject.lower()\n",
    "#     file = file.lower() \n",
    "#     if any(kw in text or kw in subject for kw in ['budget', 'invoice', 'payment', 'financial']) or 'finance' in file or 'accounting' in file:\n",
    "#         return 0  # Finance\n",
    "#     elif any(kw in text or kw in subject for kw in ['hiring', 'employee', 'benefits', 'payroll']) or 'hr' in file or 'personnel' in file:\n",
    "#         return 1  # HR\n",
    "#     elif any(kw in text or kw in subject for kw in ['contract', 'legal', 'compliance', 'attorney']) or 'legal' in file:\n",
    "#         return 2  # Legal\n",
    "#     elif any(kw in text or kw in subject for kw in ['meeting', 'schedule', 'calendar', 'agenda']) or 'meetings' in file or 'admin' in file:\n",
    "#         return 3  # Admin\n",
    "#     return 0  # Default to finance (most common in Enron)\n",
    "\n",
    "# df['category'] = df.apply(lambda x: assign_category(x['message'], x['subject'], x['file']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0126e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45496fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heuristic priority labeling\n",
    "# def assign_priority(text, subject):\n",
    "#     text = text.lower()\n",
    "#     subject = subject.lower()\n",
    "#     if any(kw in text or kw in subject for kw in ['urgent', 'asap', 'deadline', 'immediate', 'action required']) or '!' in text:\n",
    "#         return 0  # High\n",
    "#     elif any(kw in text or kw in subject for kw in ['fyi', 'thanks', 'no rush']):\n",
    "#         return 2  # Low\n",
    "#     return 1  # Medium\n",
    "\n",
    "# df['priority'] = df.apply(lambda x: assign_priority(x['message'], x['subject']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f96e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4fd4052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original category distribution:\n",
      "category\n",
      "0    9006\n",
      "1    4606\n",
      "3    3719\n",
      "2    2323\n",
      "Name: count, dtype: int64\n",
      "Category 0: Original size = 9006, Target = 4913\n",
      "Category 1: Original size = 4606, Target = 4913\n",
      "Category 2: Original size = 2323, Target = 4913\n",
      "Category 3: Original size = 3719, Target = 4913\n",
      "Balanced category distribution:\n",
      "category\n",
      "0    4913\n",
      "1    4913\n",
      "2    4913\n",
      "3    4913\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Balance categories (~25% each)\n",
    "print(\"Original category distribution:\")\n",
    "print(df['category'].value_counts())\n",
    "category_counts = df['category'].value_counts()\n",
    "target_count = int(len(df) * 0.25)\n",
    "df_cat_balanced = pd.DataFrame()\n",
    "for cat in range(4):  # 0=finance, 1=hr, 2=legal, 3=admin\n",
    "    cat_df = df[df['category'] == cat]\n",
    "    print(f\"Category {cat}: Original size = {len(cat_df)}, Target = {target_count}\")\n",
    "    if len(cat_df) > target_count:\n",
    "        cat_df = resample(cat_df, n_samples=target_count, random_state=42, replace=False)\n",
    "    elif len(cat_df) < target_count:\n",
    "        cat_df = resample(cat_df, n_samples=target_count, random_state=42, replace=True)\n",
    "        if len(cat_df) < target_count / 2:\n",
    "            print(f\"Warning: Category {cat} has very few samples ({len(cat_df)}), upsampling may cause overfitting\")\n",
    "    df_cat_balanced = pd.concat([df_cat_balanced, cat_df])\n",
    "print(\"Balanced category distribution:\")\n",
    "print(df_cat_balanced['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66ce0bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original priority distribution:\n",
      "priority\n",
      "0    10777\n",
      "1     6486\n",
      "2     2391\n",
      "Name: count, dtype: int64\n",
      "Priority 0: Original size = 10777, Target = 6485\n",
      "Priority 1: Original size = 6486, Target = 6485\n",
      "Priority 2: Original size = 2391, Target = 6485\n",
      "Balanced priority distribution:\n",
      "priority\n",
      "0    6485\n",
      "1    6485\n",
      "2    6485\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Balance priorities (~33% each)\n",
    "print(\"Original priority distribution:\")\n",
    "print(df['priority'].value_counts())\n",
    "priority_counts = df['priority'].value_counts()\n",
    "target_count = int(len(df) * 0.33)\n",
    "df_prio_balanced = pd.DataFrame()\n",
    "for prio in range(3):  # 0=high, 1=medium, 2=low\n",
    "    prio_df = df[df['priority'] == prio]\n",
    "    print(f\"Priority {prio}: Original size = {len(prio_df)}, Target = {target_count}\")\n",
    "    if len(prio_df) > target_count:\n",
    "        prio_df = resample(prio_df, n_samples=target_count, random_state=42, replace=False)\n",
    "    elif len(prio_df) < target_count:\n",
    "        prio_df = resample(prio_df, n_samples=target_count, random_state=42, replace=True)\n",
    "        if len(prio_df) < target_count / 2:\n",
    "            print(f\"Warning: Priority {prio} has very few samples ({len(prio_df)}), upsampling may cause overfitting\")\n",
    "    df_prio_balanced = pd.concat([df_prio_balanced, prio_df])\n",
    "print(\"Balanced priority distribution:\")\n",
    "print(df_prio_balanced['priority'].value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826f1e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3302c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model function\n",
    "def train_model(dataset, model_name, num_labels, output_dir, label_column, label_names):\n",
    "    # Combine subject and message for training\n",
    "    dataset['text'] = dataset.apply(lambda x: f\"[SUBJECT] {x['subject']} [BODY] {x['message']}\", axis=1)\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "        dataset['text'], dataset[label_column], test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "     # Verify labels are integers\n",
    "    train_labels = train_labels.astype(int)\n",
    "    val_labels = val_labels.astype(int)\n",
    "    \n",
    "    # Define dataset features with ClassLabel\n",
    "    features = Features({\n",
    "        'text': Value('string'),\n",
    "        'label': ClassLabel(num_classes=num_labels, names=label_names)\n",
    "    })\n",
    "    \n",
    "    train_dataset = Dataset.from_dict({'text': train_texts, 'label': train_labels}, features=features)\n",
    "    val_dataset = Dataset.from_dict({'text': val_texts, 'label': val_labels}, features=features)\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # Define id2label and label2id\n",
    "    id2label = {i: label for i, label in enumerate(label_names)}\n",
    "    label2id = {label: i for i, label in enumerate(label_names)}    \n",
    "    \n",
    "    # changed to use_safetensors = True\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels, id2label=id2label, label2id=label2id, use_safetensors=True)\n",
    "    \n",
    "    # Ensure model is in training mode and freeze base model parameters\n",
    "    model.train()\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad_(False) # Freeze base model\n",
    "    lora_config = LoraConfig(r=8, lora_alpha=16, target_modules=[\n",
    "        'query', 'key', 'value',  # Attention layers\n",
    "        'dense',  # Feed-forward layers\n",
    "        'classifier'  # Sequence classification head\n",
    "        \n",
    "        ], \n",
    "        lora_dropout=0.1, \n",
    "        bias=\"none\", \n",
    "        task_type=\"SEQ_CLS\",\n",
    "        modules_to_save=['classifier']  # Ensure classifier is saved\n",
    "        ) \n",
    "    model = get_peft_model(model, lora_config)\n",
    "    \n",
    "    # Enable gradient for both LoRA and classifier parameters\n",
    "    trainable_params = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if any(substr in name for substr in [\"lora\", \"classifier\"]):\n",
    "            param.requires_grad = True\n",
    "            trainable_params.append(name)\n",
    "    \n",
    "    # Debug: Print trainable parameters to verify\n",
    "    print(f\"Trainable parameters: {trainable_params}\")\n",
    "    \n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128) # May need to lower max_length to 64 becuase of memory\n",
    "    \n",
    "    train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "    val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "    \n",
    "    train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "    val_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])  \n",
    "    \n",
    "    # Evaluation metrics\n",
    "    def compute_metrics(p):\n",
    "        preds = p.predictions.argmax(axis=-1)\n",
    "        labels = p.label_ids\n",
    "        return {\n",
    "            \"accuracy\": accuracy_score(labels, preds),\n",
    "            \"f1\": f1_score(labels, preds, average=\"weighted\")\n",
    "        }\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        warmup_steps=50,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=f'{output_dir}/logs',\n",
    "        logging_steps=10,\n",
    "        eval_strategy='steps',\n",
    "        eval_steps=100,  # Evaluate every 100 steps\n",
    "        max_grad_norm=1.0,\n",
    "        #early_stopping_patience=3, \n",
    "        early_stopping_threshold=0.01, \n",
    "        metric_for_best_model='f1',\n",
    "        save_strategy='steps',\n",
    "        save_steps=200,\n",
    "        gradient_checkpointing=False, # set to False since LoRA handles memory optimization\n",
    "        fp16=False,\n",
    "        load_best_model_at_end=True,\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    \n",
    "     # Debug: Print training dataset features\n",
    "    print(f\"Training dataset features: {train_dataset.features}\")\n",
    "    \n",
    "    # Train and evaluate\n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    print(f\"Evaluation metrics for {output_dir}: {metrics}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    preds = trainer.predict(val_dataset)\n",
    "    cm = confusion_matrix(preds.label_ids, preds.predictions.argmax(axis=1))\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_names, yticklabels=label_names)\n",
    "    plt.title(f'Confusion Matrix - {output_dir}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "    \n",
    "    model.save_pretrained(output_dir, safe_serialization=True)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4226a99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L12-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: ['base_model.model.bert.encoder.layer.0.attention.self.query.lora_A.default.weight', 'base_model.model.bert.encoder.layer.0.attention.self.query.lora_B.default.weight', 'base_model.model.bert.encoder.layer.0.attention.self.key.lora_A.default.weight', 'base_model.model.bert.encoder.layer.0.attention.self.key.lora_B.default.weight', 'base_model.model.bert.encoder.layer.0.attention.self.value.lora_A.default.weight', 'base_model.model.bert.encoder.layer.0.attention.self.value.lora_B.default.weight', 'base_model.model.bert.encoder.layer.0.attention.output.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.0.attention.output.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.0.intermediate.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.0.intermediate.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.0.output.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.0.output.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.1.attention.self.query.lora_A.default.weight', 'base_model.model.bert.encoder.layer.1.attention.self.query.lora_B.default.weight', 'base_model.model.bert.encoder.layer.1.attention.self.key.lora_A.default.weight', 'base_model.model.bert.encoder.layer.1.attention.self.key.lora_B.default.weight', 'base_model.model.bert.encoder.layer.1.attention.self.value.lora_A.default.weight', 'base_model.model.bert.encoder.layer.1.attention.self.value.lora_B.default.weight', 'base_model.model.bert.encoder.layer.1.attention.output.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.1.attention.output.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.1.intermediate.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.1.intermediate.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.1.output.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.1.output.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.2.attention.self.query.lora_A.default.weight', 'base_model.model.bert.encoder.layer.2.attention.self.query.lora_B.default.weight', 'base_model.model.bert.encoder.layer.2.attention.self.key.lora_A.default.weight', 'base_model.model.bert.encoder.layer.2.attention.self.key.lora_B.default.weight', 'base_model.model.bert.encoder.layer.2.attention.self.value.lora_A.default.weight', 'base_model.model.bert.encoder.layer.2.attention.self.value.lora_B.default.weight', 'base_model.model.bert.encoder.layer.2.attention.output.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.2.attention.output.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.2.intermediate.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.2.intermediate.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.2.output.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.2.output.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.3.attention.self.query.lora_A.default.weight', 'base_model.model.bert.encoder.layer.3.attention.self.query.lora_B.default.weight', 'base_model.model.bert.encoder.layer.3.attention.self.key.lora_A.default.weight', 'base_model.model.bert.encoder.layer.3.attention.self.key.lora_B.default.weight', 'base_model.model.bert.encoder.layer.3.attention.self.value.lora_A.default.weight', 'base_model.model.bert.encoder.layer.3.attention.self.value.lora_B.default.weight', 'base_model.model.bert.encoder.layer.3.attention.output.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.3.attention.output.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.3.intermediate.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.3.intermediate.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.3.output.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.3.output.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.4.attention.self.query.lora_A.default.weight', 'base_model.model.bert.encoder.layer.4.attention.self.query.lora_B.default.weight', 'base_model.model.bert.encoder.layer.4.attention.self.key.lora_A.default.weight', 'base_model.model.bert.encoder.layer.4.attention.self.key.lora_B.default.weight', 'base_model.model.bert.encoder.layer.4.attention.self.value.lora_A.default.weight', 'base_model.model.bert.encoder.layer.4.attention.self.value.lora_B.default.weight', 'base_model.model.bert.encoder.layer.4.attention.output.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.4.attention.output.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.4.intermediate.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.4.intermediate.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.4.output.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.4.output.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.5.attention.self.query.lora_A.default.weight', 'base_model.model.bert.encoder.layer.5.attention.self.query.lora_B.default.weight', 'base_model.model.bert.encoder.layer.5.attention.self.key.lora_A.default.weight', 'base_model.model.bert.encoder.layer.5.attention.self.key.lora_B.default.weight', 'base_model.model.bert.encoder.layer.5.attention.self.value.lora_A.default.weight', 'base_model.model.bert.encoder.layer.5.attention.self.value.lora_B.default.weight', 'base_model.model.bert.encoder.layer.5.attention.output.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.5.attention.output.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.5.intermediate.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.5.intermediate.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.5.output.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.5.output.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.6.attention.self.query.lora_A.default.weight', 'base_model.model.bert.encoder.layer.6.attention.self.query.lora_B.default.weight', 'base_model.model.bert.encoder.layer.6.attention.self.key.lora_A.default.weight', 'base_model.model.bert.encoder.layer.6.attention.self.key.lora_B.default.weight', 'base_model.model.bert.encoder.layer.6.attention.self.value.lora_A.default.weight', 'base_model.model.bert.encoder.layer.6.attention.self.value.lora_B.default.weight', 'base_model.model.bert.encoder.layer.6.attention.output.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.6.attention.output.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.6.intermediate.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.6.intermediate.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.6.output.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.6.output.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.7.attention.self.query.lora_A.default.weight', 'base_model.model.bert.encoder.layer.7.attention.self.query.lora_B.default.weight', 'base_model.model.bert.encoder.layer.7.attention.self.key.lora_A.default.weight', 'base_model.model.bert.encoder.layer.7.attention.self.key.lora_B.default.weight', 'base_model.model.bert.encoder.layer.7.attention.self.value.lora_A.default.weight', 'base_model.model.bert.encoder.layer.7.attention.self.value.lora_B.default.weight', 'base_model.model.bert.encoder.layer.7.attention.output.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.7.attention.output.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.7.intermediate.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.7.intermediate.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.7.output.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.7.output.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.8.attention.self.query.lora_A.default.weight', 'base_model.model.bert.encoder.layer.8.attention.self.query.lora_B.default.weight', 'base_model.model.bert.encoder.layer.8.attention.self.key.lora_A.default.weight', 'base_model.model.bert.encoder.layer.8.attention.self.key.lora_B.default.weight', 'base_model.model.bert.encoder.layer.8.attention.self.value.lora_A.default.weight', 'base_model.model.bert.encoder.layer.8.attention.self.value.lora_B.default.weight', 'base_model.model.bert.encoder.layer.8.attention.output.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.8.attention.output.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.8.intermediate.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.8.intermediate.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.8.output.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.8.output.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.9.attention.self.query.lora_A.default.weight', 'base_model.model.bert.encoder.layer.9.attention.self.query.lora_B.default.weight', 'base_model.model.bert.encoder.layer.9.attention.self.key.lora_A.default.weight', 'base_model.model.bert.encoder.layer.9.attention.self.key.lora_B.default.weight', 'base_model.model.bert.encoder.layer.9.attention.self.value.lora_A.default.weight', 'base_model.model.bert.encoder.layer.9.attention.self.value.lora_B.default.weight', 'base_model.model.bert.encoder.layer.9.attention.output.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.9.attention.output.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.9.intermediate.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.9.intermediate.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.9.output.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.9.output.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.10.attention.self.query.lora_A.default.weight', 'base_model.model.bert.encoder.layer.10.attention.self.query.lora_B.default.weight', 'base_model.model.bert.encoder.layer.10.attention.self.key.lora_A.default.weight', 'base_model.model.bert.encoder.layer.10.attention.self.key.lora_B.default.weight', 'base_model.model.bert.encoder.layer.10.attention.self.value.lora_A.default.weight', 'base_model.model.bert.encoder.layer.10.attention.self.value.lora_B.default.weight', 'base_model.model.bert.encoder.layer.10.attention.output.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.10.attention.output.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.10.intermediate.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.10.intermediate.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.10.output.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.10.output.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.11.attention.self.query.lora_A.default.weight', 'base_model.model.bert.encoder.layer.11.attention.self.query.lora_B.default.weight', 'base_model.model.bert.encoder.layer.11.attention.self.key.lora_A.default.weight', 'base_model.model.bert.encoder.layer.11.attention.self.key.lora_B.default.weight', 'base_model.model.bert.encoder.layer.11.attention.self.value.lora_A.default.weight', 'base_model.model.bert.encoder.layer.11.attention.self.value.lora_B.default.weight', 'base_model.model.bert.encoder.layer.11.attention.output.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.11.attention.output.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.11.intermediate.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.11.intermediate.dense.lora_B.default.weight', 'base_model.model.bert.encoder.layer.11.output.dense.lora_A.default.weight', 'base_model.model.bert.encoder.layer.11.output.dense.lora_B.default.weight', 'base_model.model.bert.pooler.dense.lora_A.default.weight', 'base_model.model.bert.pooler.dense.lora_B.default.weight', 'base_model.model.classifier.original_module.weight', 'base_model.model.classifier.original_module.bias', 'base_model.model.classifier.modules_to_save.default.weight', 'base_model.model.classifier.modules_to_save.default.bias']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a529ba70c48408d9c029310bd9e87a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15721 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e39091e62b4d8ca3141801e8f3b70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3931 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'early_stopping_patience'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train category classifier\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# changed model to sentence-transformers/all-MiniLM-L12-v2 from microsoft/minilm-l12-h384-uncased\u001b[39;00m\n\u001b[32m      3\u001b[39m category_label_names = [\u001b[33m\"\u001b[39m\u001b[33mFinance\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mHR\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mLegal\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAdmin\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m model_cat, tokenizer_cat = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf_cat_balanced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msentence-transformers/all-MiniLM-L12-v2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./fine_tuned_minilm_category\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcategory\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategory_label_names\u001b[49m\u001b[43m)\u001b[49m \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(dataset, model_name, num_labels, output_dir, label_column, label_names)\u001b[39m\n\u001b[32m     70\u001b[39m     labels = p.label_ids\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     72\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m: accuracy_score(labels, preds),\n\u001b[32m     73\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mf1\u001b[39m\u001b[33m\"\u001b[39m: f1_score(labels, preds, average=\u001b[33m\"\u001b[39m\u001b[33mweighted\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     74\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m training_args = \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moutput_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/logs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msteps\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Evaluate every 100 steps\u001b[39;49;00m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_grad_norm\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric_for_best_model\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mf1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msteps\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgradient_checkpointing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# set to False since LoRA handles memory optimization\u001b[39;49;00m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfp16\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_best_model_at_end\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m trainer = Trainer(\n\u001b[32m     99\u001b[39m     model=model,\n\u001b[32m    100\u001b[39m     args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m     compute_metrics=compute_metrics\n\u001b[32m    104\u001b[39m )\n\u001b[32m    106\u001b[39m  \u001b[38;5;66;03m# Debug: Print training dataset features\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: TrainingArguments.__init__() got an unexpected keyword argument 'early_stopping_patience'"
     ]
    }
   ],
   "source": [
    "# Train category classifier\n",
    "# changed model to sentence-transformers/all-MiniLM-L12-v2 from microsoft/minilm-l12-h384-uncased\n",
    "category_label_names = [\"Finance\", \"HR\", \"Legal\", \"Admin\"]\n",
    "model_cat, tokenizer_cat = train_model(\n",
    "    df_cat_balanced, 'sentence-transformers/all-MiniLM-L12-v2', 4, './fine_tuned_minilm_category', 'category', category_label_names) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cbb46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train priority classifier\n",
    "# changed model to sentence-transformers/all-MiniLM-L12-v2 from microsoft/minilm-l12-h384-uncased\n",
    "priority_label_names = [\"High\", \"Medium\", \"Low\"]\n",
    "model_prio, tokenizer_prio = train_model(\n",
    "    df_prio_balanced, 'sentence-transformers/all-MiniLM-L12-v2', 3, './fine_tuned_minilm_priority', 'priority', priority_label_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b72e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference functions\n",
    "def predict_category(email_text, model=model_cat, tokenizer=tokenizer_cat):\n",
    "    text, subject = clean_email(email_text)\n",
    "    input_text = f\"[SUBJECT] {subject} [BODY] {text}\"\n",
    "    inputs = tokenizer(input_text, return_tensors='pt', truncation=True, padding=True, max_length=64)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    predicted_class = torch.argmax(outputs.logits, dim=1).item()\n",
    "    return category_label_names[predicted_class]\n",
    "\n",
    "def predict_priority(email_text, model=model_prio, tokenizer=tokenizer_prio):\n",
    "    text, subject = clean_email(email_text)\n",
    "    input_text = f\"[SUBJECT] {subject} [BODY] {text}\"\n",
    "    inputs = tokenizer(input_text, return_tensors='pt', truncation=True, padding=True, max_length=64)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    predicted_class = torch.argmax(outputs.logits, dim=1).item()\n",
    "    return priority_label_names[predicted_class]\n",
    "\n",
    "# Test inference\n",
    "sample_email = \"Subject: Budget Review\\nDate: Wed, 29 Nov 2000 05:40:00 -0800\\nPlease review the attached budget for Q3.\"\n",
    "print(f\"Category: {predict_category(sample_email)}\")\n",
    "print(f\"Priority: {predict_priority(sample_email)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
